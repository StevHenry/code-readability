{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load the Boston Housing dataset\n",
    "boston = load_boston()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.2, random_state=12345)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest cross-validation mean squared error: 10.566\n",
      "Random Forest Regressor MSE: 9.698\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regressor\n",
    "reg_rf = RandomForestRegressor(n_estimators=100, random_state=12345)\n",
    "reg_rf.fit(X_train, y_train)\n",
    "y_pred_rf = reg_rf.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "\n",
    "# Perform cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=12345)\n",
    "cv_scores = cross_val_score(reg_rf, X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = -np.mean(cv_scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"Random Forest cross-validation mean squared error: {:.3f}\".format(mse))\n",
    "print(\"Random Forest Regressor MSE: {:.3f}\".format(mse_rf))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression cross-validation mean squared error: 23.456\n",
      "Linear Regression mean squared error: 24.622\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "reg_lr = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "reg_lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_lr = reg_lr.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "\n",
    "# Perform cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=12345)\n",
    "cv_scores = cross_val_score(reg_lr, X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = -np.mean(cv_scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"Linear Regression cross-validation mean squared error: {:.3f}\".format(mse))\n",
    "print(\"Linear Regression mean squared error: {:.3f}\".format(mse_lr))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurol networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_4784\\1773406941.py:37: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = KerasRegressor(build_fn=create_model, epochs=50, batch_size=32, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000158E0C730D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Neural Network cross-validation mean squared error: 23.611\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 15.6014\n",
      "Test loss: 15.601410865783691\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the neural network model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_shape=X_train.shape[1:], activation=\"relu\"))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "    return model\n",
    "\n",
    "# Create the KerasRegressor object\n",
    "keras_reg = KerasRegressor(build_fn=create_model, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Perform cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=12345)\n",
    "cv_scores = cross_val_score(keras_reg, X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = -np.mean(cv_scores)\n",
    "\n",
    "# Print the result\n",
    "print(\"Neural Network cross-validation mean squared error: {:.3f}\".format(mse))\n",
    "\n",
    "# Train the model\n",
    "history = keras_reg.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = keras_reg.score(X_test, y_test)\n",
    "print(\"Test loss:\", loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
